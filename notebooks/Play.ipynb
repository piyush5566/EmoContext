{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ],
     "output_type": "error"
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ],
     "output_type": "error"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division \n",
    "import json                                     \n",
    "import csv                                      \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer                                       \n",
    "from deepmoji.model_def import deepmoji_feature_encoding                                        \n",
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers import Dense\n",
    "import pickle\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing using dictionary from /app/DeepMoji/model/vocabulary.json\n",
      "Loading model from /tmp/DeepMoji/model/deepmoji_weights.hdf5.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1370: calling reduce_all (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Loading weights for embedding\n",
      "Loading weights for bi_lstm_0\n",
      "Loading weights for bi_lstm_1\n",
      "Loading weights for attlayer\n",
      "Ignoring weights for softmax\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 256)      12800000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20, 256)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 20, 1024)     3149824     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 20, 1024)     6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 2304)     0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 22,247,680\n",
      "Trainable params: 22,247,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20                                     \n",
    "batch_size = 32                                 \n",
    "\n",
    "print('Tokenizing using dictionary from {}'.format('/app/DeepMoji/model/vocabulary.json'))                                 \n",
    "with open('/app/DeepMoji/model/vocabulary.json', 'r') as f:                \n",
    "    vocabulary = json.load(f)     \n",
    "    \n",
    "print('Loading model from {}.'.format(PRETRAINED_PATH))                                         \n",
    "model = deepmoji_feature_encoding(maxlen, '/app/DeepMoji/model/deepmoji_weights.hdf5')                                      \n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   18    87  3497  1864     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   18    87    79    13   122   935    85    34     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   18    87 11824    31    41  5113     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   18    87  3745    31  2324   440    50     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   18    87    13    12   111   102    42   642    34     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   22    28   172     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [   22    28    10   172     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n",
      "Encoding texts..\n",
      "First 5 dimensions for sentence: I love messing with yo mind!!\n",
      "[[-0.0085292   0.0586118  -0.         ...,  0.06065543 -0.04092088\n",
      "   0.00691591]\n",
      " [-0.07870144  0.0667949  -0.00099716 ...,  0.03007438 -0.0441251\n",
      "   0.04340452]\n",
      " [-0.00871689 -0.02312152 -0.         ..., -0.00790952 -0.02549067\n",
      "   0.0305871 ]\n",
      " ..., \n",
      " [-0.05878516  0.03383959 -0.00916662 ...,  0.00510872 -0.04704075\n",
      "  -0.00806762]\n",
      " [ 0.06580106  0.00353238  0.00688199 ..., -0.0360502   0.00049157\n",
      "  -0.11248691]\n",
      " [-0.01482751 -0.00069204  0.0205245  ..., -0.04551451  0.00133792\n",
      "  -0.05233878]]\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCES = [u'I love mom\\'s cooking',     \n",
    "                  u'I love how you never reply back..',                                         \n",
    "                  u'I love cruising with my homies',                                            \n",
    "                  u'I love messing with yo mind!!',                                             \n",
    "                  u'I love you and now you\\'re just gone..',                                    \n",
    "                  u'This is shit',              \n",
    "                  u'This is the shit']  \n",
    "st = SentenceTokenizer(vocabulary, maxlen)      \n",
    "tokenized, _, _ = st.tokenize_sentences(TEST_SENTENCES)                                                                      \n",
    "print(tokenized)\n",
    "print('Encoding texts..')                       \n",
    "encoding = model.predict(tokenized)             \n",
    "\n",
    "print('First 5 dimensions for sentence: {}'.format(TEST_SENTENCES[3]))                          \n",
    "print(encoding)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  turn1  \\\n",
       "0   0  Don't worry  I'm girl   \n",
       "1   1            When did I?   \n",
       "2   2                     By   \n",
       "3   3         U r ridiculous   \n",
       "4   4     Just for time pass   \n",
       "\n",
       "                                               turn2  \\\n",
       "0                       hmm how do I know if you are   \n",
       "1                         saw many times i think -_-   \n",
       "2                                   by Google Chrome   \n",
       "3  I might be ridiculous but I am telling the truth.   \n",
       "4                         wt do u do 4 a living then   \n",
       "\n",
       "                       turn3   label  \n",
       "0            What's ur name?  others  \n",
       "1        No. I never saw you   angry  \n",
       "2             Where you live  others  \n",
       "3  U little disgusting whore   angry  \n",
       "4                      Maybe  others  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.txt',sep='\\t',header=(0), encoding = 'utf8')\n",
    "df.set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30160"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tokenized, _, _ = st.tokenize_sentences([df['turn1'][i],df['turn2'][i],df['turn3'][i]]) \n",
    "    encoding = model.predict(tokenized) \n",
    "    x.append(encoding)\n",
    "    y.append(df['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30160\n",
      "30160\n"
     ]
    }
   ],
   "source": [
    "print(len(x_))\n",
    "print(len(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2304/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_test', 'wb') as f:\n",
    "    pickle.dump(x, f)\n",
    "with open('y_test', 'wb') as f:\n",
    "    pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_test', 'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "with open('y_test', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label2emotion = {0:\"others\", 1:\"happy\", 2: \"sad\", 3:\"angry\"}\n",
    "emotion2label = {\"others\":0, \"happy\":1, \"sad\":2, \"angry\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    y[i] = emotion2label[y[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    x[i] = np.concatenate(x[i], axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30160"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20207 9953\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(6912,))\n",
    "model = Dense(3951, activation='relu')(inputs)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(1024, activation='relu')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "model = Dense(512, activation='relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(64, activation='relu')(model)\n",
    "predictions = Dense(4, activation='softmax')(model)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20207 samples, validate on 9953 samples\n",
      "Epoch 1/10\n",
      "20207/20207 [==============================] - 13s 663us/step - loss: 0.5508 - acc: 0.7996 - val_loss: 0.4260 - val_acc: 0.8536\n",
      "Epoch 2/10\n",
      "20207/20207 [==============================] - 12s 591us/step - loss: 0.3876 - acc: 0.8655 - val_loss: 0.3722 - val_acc: 0.8654\n",
      "Epoch 3/10\n",
      "20207/20207 [==============================] - 12s 588us/step - loss: 0.3382 - acc: 0.8858 - val_loss: 0.4288 - val_acc: 0.8503\n",
      "Epoch 4/10\n",
      "20207/20207 [==============================] - 12s 588us/step - loss: 0.3062 - acc: 0.8963 - val_loss: 0.4804 - val_acc: 0.8682\n",
      "Epoch 5/10\n",
      "20207/20207 [==============================] - 12s 591us/step - loss: 0.2731 - acc: 0.9134 - val_loss: 0.4505 - val_acc: 0.8646\n",
      "Epoch 6/10\n",
      "20207/20207 [==============================] - 12s 592us/step - loss: 0.2536 - acc: 0.9257 - val_loss: 0.4376 - val_acc: 0.8707\n",
      "Epoch 7/10\n",
      "20207/20207 [==============================] - 12s 589us/step - loss: 0.2168 - acc: 0.9347 - val_loss: 0.5635 - val_acc: 0.8676\n",
      "Epoch 8/10\n",
      "20207/20207 [==============================] - 12s 590us/step - loss: 0.2114 - acc: 0.9405 - val_loss: 0.5954 - val_acc: 0.8674\n",
      "Epoch 9/10\n",
      "20207/20207 [==============================] - 12s 590us/step - loss: 0.1908 - acc: 0.9496 - val_loss: 0.7391 - val_acc: 0.8598\n",
      "Epoch 10/10\n",
      "20207/20207 [==============================] - 12s 590us/step - loss: 0.1742 - acc: 0.9572 - val_loss: 0.6730 - val_acc: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c9f9b3c50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train),\n",
    "          y_train,\n",
    "          validation_data=(np.array(x_test),y_test),\n",
    "          shuffle=True,\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_integers = np.argmax(y, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ = model.predict(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives per class :  [ 4428.  1114.  1553.  1569.]\n",
      "False Positives per class :  [ 536.  271.  237.  245.]\n",
      "False Negatives per class :  [ 499.  257.  275.  258.]\n",
      "Class happy : Precision : 0.804, Recall : 0.813, F1 : 0.808\n",
      "Class sad : Precision : 0.868, Recall : 0.850, F1 : 0.858\n",
      "Class angry : Precision : 0.865, Recall : 0.859, F1 : 0.862\n",
      "Ignoring the Others class, Macro Precision : 0.8456, Macro Recall : 0.8403, Macro F1 : 0.8430\n",
      "Ignoring the Others class, Micro TP : 4236, FP : 753, FN : 790\n",
      "Accuracy : 0.8705, Micro Precision : 0.8491, Micro Recall : 0.8428, Micro F1 : 0.8459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8704913091530192,\n",
       " 0.84906794948887554,\n",
       " 0.84281734978113809,\n",
       " 0.84593110334498256)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMetrics(predictions_,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.50441530639550447,\n",
       " 1: 1.7770445439547491,\n",
       " 2: 1.3801940325828299,\n",
       " 3: 1.3694151834362513}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(predictions, ground):\n",
    "    \"\"\"Given predicted labels and the respective ground truth labels, display some metrics\n",
    "    Input: shape [# of samples, NUM_CLASSES]\n",
    "        predictions : Model output. Every row has 4 decimal values, with the highest belonging to the predicted class\n",
    "        ground : Ground truth labels, converted to one-hot encodings. A sample belonging to Happy class will be [0, 1, 0, 0]\n",
    "    Output:\n",
    "        accuracy : Average accuracy\n",
    "        microPrecision : Precision calculated on a micro level. Ref - https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
    "        microRecall : Recall calculated on a micro level\n",
    "        microF1 : Harmonic mean of microPrecision and microRecall. Higher value implies better classification  \n",
    "    \"\"\"\n",
    "    # [0.1, 0.3 , 0.2, 0.1] -> [0, 1, 0, 0]\n",
    "    discretePredictions = to_categorical(predictions.argmax(axis=1))\n",
    "    \n",
    "    truePositives = np.sum(discretePredictions*ground, axis=0)\n",
    "    falsePositives = np.sum(np.clip(discretePredictions - ground, 0, 1), axis=0)\n",
    "    falseNegatives = np.sum(np.clip(ground-discretePredictions, 0, 1), axis=0)\n",
    "    \n",
    "    print(\"True Positives per class : \", truePositives)\n",
    "    print(\"False Positives per class : \", falsePositives)\n",
    "    print(\"False Negatives per class : \", falseNegatives)\n",
    "    \n",
    "    # ------------- Macro level calculation ---------------\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    # We ignore the \"Others\" class during the calculation of Precision, Recall and F1\n",
    "    for c in range(1, 4):\n",
    "        precision = truePositives[c] / (truePositives[c] + falsePositives[c])\n",
    "        macroPrecision += precision\n",
    "        recall = truePositives[c] / (truePositives[c] + falseNegatives[c])\n",
    "        macroRecall += recall\n",
    "        f1 = ( 2 * recall * precision ) / (precision + recall) if (precision+recall) > 0 else 0\n",
    "        print(\"Class %s : Precision : %.3f, Recall : %.3f, F1 : %.3f\" % (label2emotion[c], precision, recall, f1))\n",
    "    \n",
    "    macroPrecision /= 3\n",
    "    macroRecall /= 3\n",
    "    macroF1 = (2 * macroRecall * macroPrecision ) / (macroPrecision + macroRecall) if (macroPrecision+macroRecall) > 0 else 0\n",
    "    print(\"Ignoring the Others class, Macro Precision : %.4f, Macro Recall : %.4f, Macro F1 : %.4f\" % (macroPrecision, macroRecall, macroF1))   \n",
    "    \n",
    "    # ------------- Micro level calculation ---------------\n",
    "    truePositives = truePositives[1:].sum()\n",
    "    falsePositives = falsePositives[1:].sum()\n",
    "    falseNegatives = falseNegatives[1:].sum()    \n",
    "    \n",
    "    print(\"Ignoring the Others class, Micro TP : %d, FP : %d, FN : %d\" % (truePositives, falsePositives, falseNegatives))\n",
    "    \n",
    "    microPrecision = truePositives / (truePositives + falsePositives)\n",
    "    microRecall = truePositives / (truePositives + falseNegatives)\n",
    "    \n",
    "    microF1 = ( 2 * microRecall * microPrecision ) / (microPrecision + microRecall) if (microPrecision+microRecall) > 0 else 0\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    ground = ground.argmax(axis=1)\n",
    "    accuracy = np.mean(predictions==ground)\n",
    "    \n",
    "    print(\"Accuracy : %.4f, Micro Precision : %.4f, Micro Recall : %.4f, Micro F1 : %.4f\" % (accuracy, microPrecision, microRecall, microF1))\n",
    "    return accuracy, microPrecision, microRecall, microF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.00000000e+00,   2.64081920e-36,   1.88661535e-38,\n",
       "          1.94478207e-22],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       ..., \n",
       "       [  1.35437906e-01,   1.37659383e-03,   4.68777418e-01,\n",
       "          3.94408107e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  9.96649802e-01,   2.25211587e-03,   3.94858507e-04,\n",
       "          7.03235390e-04]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
