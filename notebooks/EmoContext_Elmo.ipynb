{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmoContext",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "aYVd26q1_3xW"
      },
      "cell_type": "markdown",
      "source": [
        "# NLP Project: EmoContext\n",
        "\n",
        "This notebooks explores the use of of `elmo` embedding for our task , EmoContext. \n",
        "\n",
        "We have tried the following models in this part:\n",
        "- LSTM\n",
        "- CNN\n",
        "- CNN->LSTM\n",
        "\n",
        "**Conclusion**:\n",
        "Using LSTM gave slightly better ouput than the other approaches.\n",
        "\n",
        "\n",
        "**Note:** You need to upload the training file: `train.txt` in the current folder. "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xOATihhH1IxS"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing the environment\n",
        "\n",
        "\n",
        "You need to upload the training file: `train.txt` in the current folder. \n",
        "And `devwithoutlabels.txt` needs to be present for testing purposes."
      ]
    },
    {
      "metadata": {
        "cellView": "code",
        "colab_type": "code",
        "id": "_8N3Hx2dyUC-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Install the latest Tensorflow version.\n",
        "# !pip install --quiet \"tensorflow>=1.7\"\n",
        "# # Install TF-Hub.\n",
        "# !pip install tensorflow-hub\n",
        "# !pip install seaborn\n",
        "# !pip install keras\n",
        "! pip install tensorboardcolab\n",
        "! apt-get -qq install -y graphviz && pip3 install -q pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v7hy0bhngTUp",
        "outputId": "5002ef73-91cb-40f0-c7ff-03f2cd6ecbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import keras.backend as K\n",
        "import io\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Bidirectional, LSTM\n",
        "from keras.layers import Embedding, Concatenate, Input, Lambda, Dense, Dropout, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3_vYw8j8Mp4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "sdW0O5B9Mo8A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# labels\n",
        "label2emotion = {0: \"others\", 1: \"happy\", 2: \"sad\", 3: \"angry\"}\n",
        "emotion2label = {\"others\": 0, \"happy\": 1, \"sad\": 2, \"angry\": 3}\n",
        "\n",
        "def preprocessData(dataFilePath, mode):\n",
        "    \"\"\"Load data from a file, process and return indices, conversations and labels in separate lists\n",
        "    Input:\n",
        "        dataFilePath : Path to train/test file to be processed\n",
        "        mode : \"train\" mode returns labels. \"test\" mode doesn't return labels.\n",
        "    Output:\n",
        "        indices : Unique conversation ID list\n",
        "        conversations : List of 3 turn conversations, processed and each turn separated by the <eos> tag\n",
        "        labels : [Only available in  \"train\" mode] List of labels\n",
        "    \"\"\"\n",
        "    indices = []\n",
        "    conversations = []\n",
        "    labels = []\n",
        "    with io.open(dataFilePath, encoding=\"utf8\") as finput:\n",
        "        finput.readline()\n",
        "        for line in finput:\n",
        "#             # Convert multiple instances of . ? ! , to single instance\n",
        "#             # okay...sure -> okay . sure\n",
        "#             # okay???sure -> okay ? sure\n",
        "#             # Add whitespace around such punctuation\n",
        "#             # okay!sure -> okay ! sure\n",
        "#             repeatedChars = ['.', '?', '!', ',']\n",
        "#             for c in repeatedChars:\n",
        "#                 lineSplit = line.split(c)\n",
        "#                 while True:\n",
        "#                     try:\n",
        "#                         lineSplit.remove('')\n",
        "#                     except:\n",
        "#                         break\n",
        "#                 cSpace = ' ' + c + ' '\n",
        "#                 line = cSpace.join(lineSplit)\n",
        "\n",
        "            line = line.strip().split('\\t')\n",
        "            if mode == \"train\":\n",
        "              # Train data contains id, 3 turns and label\n",
        "              label = emotion2label[line[4]]\n",
        "              labels.append(label)\n",
        "\n",
        "                \n",
        "#             conv = ' <eos> '.join(line[1:4])\n",
        "\n",
        "            # Remove any duplicate spaces\n",
        "#             duplicateSpacePattern = re.compile(r'\\ +')\n",
        "#             conv = re.sub(duplicateSpacePattern, ' ', conv)\n",
        "\n",
        "            indices.append(int(line[0]))\n",
        "            conversations.append(line[1:4])\n",
        "\n",
        "    if mode == \"train\":\n",
        "        return np.array(indices), np.array(conversations), np.array(labels)\n",
        "    else:\n",
        "        return np.array(indices), np.array(conversations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDE07tc3NQYf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices, conversations, labels = preprocessData('train.txt', mode='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QP1OJ_TuRdzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = to_categorical(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NzjZRe_GQuxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(conversations,Y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=Y,\n",
        "                                                    random_state=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFOmX_blNQcz",
        "colab_type": "code",
        "outputId": "2d174c7a-7ac9-41ae-9a29-ead6245882e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ekpJFzd4Zp-D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def get_meld_sent():\n",
        "  \n",
        "#   import pandas as pd\n",
        "#   ! wget \"https://raw.githubusercontent.com/SenticNet/MELD/master/data/MELD/train_sent_emo.csv\"\n",
        "#   df_train = pd.read_csv('train_sent_emo.csv')\n",
        "  \n",
        "#   X = []\n",
        "#   Y = []\n",
        "  \n",
        "#   for i  in range(len(df_train)):\n",
        "#     big_dialogue = df_train.loc[df_train['Dialogue_ID'] == 2].set_index(['Utterance_ID'])\n",
        "#     for j in range(len(big_dialogue)-3):\n",
        "#       x = [big_dialogue.iloc[j]['Utterance'],\n",
        "#        big_dialogue.iloc[j+1]['Utterance'],\n",
        "#        big_dialogue.iloc[j+2]['Utterance']]\n",
        "#       y = big_dialogue.iloc[j+2]['Emotion']\n",
        "\n",
        "#       X.append(x)\n",
        "#       Y.append(y)\n",
        "   \n",
        "#   #emotion2label = {\"neutral\": 0, \"joy\": 1, \"sadness\": 2, \"disgust\": 3, \"surprise\":0}\n",
        "#   # = {\"others\": 0, \"happy\": 1, \"sad\": 2, \"angry\": 3}\n",
        "  \n",
        "#   #for i in range(len(Y)):\n",
        "#   #  Y[i] = emotion2label[Y[i]]\n",
        "  \n",
        "#   return X, Y\n",
        "  \n",
        "# meld_train_x, meld_train_y = get_meld_sent()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nS6ag9XZxa_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def get_meld_sent():\n",
        "  \n",
        "#   import pandas as pd\n",
        "#   ! wget \"https://raw.githubusercontent.com/SenticNet/MELD/master/data/MELD/test_sent_emo.csv\"\n",
        "#   df_train = pd.read_csv('test_sent_emo.csv')\n",
        "  \n",
        "#   X = []\n",
        "#   Y = []\n",
        "  \n",
        "#   for i  in range(len(df_train)):\n",
        "#     big_dialogue = df_train.loc[df_train['Dialogue_ID'] == 2].set_index(['Utterance_ID'])\n",
        "#     for j in range(len(big_dialogue)-3):\n",
        "#       x = [big_dialogue.iloc[j]['Utterance'],\n",
        "#        big_dialogue.iloc[j+1]['Utterance'],\n",
        "#        big_dialogue.iloc[j+2]['Utterance']]\n",
        "#       y = big_dialogue.iloc[j+2]['Emotion']\n",
        "\n",
        "#       X.append(x)\n",
        "#       Y.append(y)\n",
        "   \n",
        "#   #emotion2label = {\"neutral\": 0, \"joy\": 1,\"anger\":3, \"sadness\": 2, \"disgust\": 3, \"surprise\":0}\n",
        "#   # = {\"others\": 0, \"happy\": 1, \"sad\": 2, \"angry\": 3}\n",
        "  \n",
        "#   #for i in range(len(Y)):\n",
        "#   #    Y[i] = emotion2label[Y[i]]\n",
        "  \n",
        "#   return X, Y\n",
        "  \n",
        "# meld_test_x, meld_test_y = get_meld_sent()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWkN19y_cjLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# meld_test_x = np.array(meld_test_x)\n",
        "# meld_train_x = np.array(meld_train_x)\n",
        "# print(meld_train_x.shape)\n",
        "# print(meld_test_x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KPhdtDATXSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import LabelBinarizer\n",
        "# encoder = LabelBinarizer()\n",
        "# meld_test_y = encoder.fit_transform(meld_test_y)\n",
        "# meld_test_y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SlbO6flderxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encoder = LabelBinarizer()\n",
        "# meld_train_y = encoder.fit_transform(meld_train_y)\n",
        "# meld_train_y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JuzCCG9LSojx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_class_weight(y):\n",
        "    \"\"\"\n",
        "\n",
        "    Used from: https://stackoverflow.com/a/50695814\n",
        "    TODO: check validity and 'balanced' option\n",
        "    :param y: A list of one-hot-encoding labels [[0,0,1,0],[0,0,0,1],..]\n",
        "    :return: class-weights to be used by keras model.fit(.. class_weight=\"\") -> {0:0.52134, 1:1.adas..}\n",
        "    \"\"\"\n",
        "    y_integers = np.argmax(y, axis=1)\n",
        "    class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
        "    d_class_weights = dict(enumerate(class_weights))\n",
        "    return d_class_weights\n",
        "class_weights = get_class_weight(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WhBMWVIrQOjO",
        "colab_type": "code",
        "outputId": "dc14c64a-62a9-4ae8-bf69-70a27c54d4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5044153063955045,\n",
              " 1: 1.777044543954749,\n",
              " 2: 1.38019403258283,\n",
              " 3: 1.3694151834362513}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "KwMk9QyH_zAa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8w2ycp08NfJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elmo "
      ]
    },
    {
      "metadata": {
        "id": "w6u-c9hA8PVd",
        "colab_type": "code",
        "outputId": "4d72636b-da08-4ef0-da97-6f1d5ff4b619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# downloading emlo\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gJvxTvO8Ehmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n",
        "Choose the model you want to try by specifying the `MODEL_ID`.  \n",
        "\n",
        "1 -> JUST CNN  \n",
        "2 -> JUST LSTM  \n",
        "3 -> BOTH CNN + LSTM   "
      ]
    },
    {
      "metadata": {
        "id": "Tel9_iufPQm3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_ID = 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DI3cVqL5Es8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 1024\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 10\n",
        "\n",
        "NUMBER_OF_FILTERS = [128]\n",
        "KERNEL_SIZE = [4]\n",
        "lstm_output_size = 128\n",
        "HIDDEN_LAYER = 128\n",
        "SIMILARITY_LAYER = 62\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E85-XKpMMmWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_embedding(in_str):\n",
        "  return elmo(tf.squeeze(tf.cast(in_str, tf.string)), signature=\"default\", as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "75ZqMPjCE0A9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embedded_cnn(x):\n",
        "    # Embedding Layer\n",
        "    emdded = Lambda(get_embedding, output_shape=(None,EMBEDDING_DIM))(x)\n",
        "\n",
        "    # 1D Conv Layer with multiple possible kernel sizes\n",
        "    conv_layers = []\n",
        "    for n_gram, hidden_units in zip(KERNEL_SIZE, NUMBER_OF_FILTERS):\n",
        "        # 1D Conv with kernel size of n_gram(and with hidden_units of those filters)\n",
        "        \n",
        "        \n",
        "        conv_layer = Conv1D(filters=hidden_units,\n",
        "                            kernel_size=n_gram,\n",
        "                            padding='valid',\n",
        "                            activation='relu')(emdded)\n",
        "\n",
        "        conv_layer = MaxPooling1D()(conv_layer)\n",
        "        \n",
        "        if MODEL_ID ==  3:\n",
        "          conv_layer = LSTM(lstm_output_size, dropout=0.5)(conv_layer)\n",
        "          \n",
        "        if MODEL_ID == 2:\n",
        "          conv_layer = LSTM(lstm_output_size, dropout=0.5)(emdded)\n",
        "        \n",
        "        conv_layers.append(conv_layer)\n",
        "\n",
        "    if len(conv_layers) == 1:\n",
        "        return conv_layers[0]\n",
        "    else:\n",
        "        # Concatenates conv layers with  different filter sizes\n",
        "        all_conv_layers_merged = Concatenate()(conv_layers)\n",
        "        return all_conv_layers_merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abzedWPtE1AN",
        "colab_type": "code",
        "outputId": "a35dcb85-6f76-4194-b4de-1cd4e7a03b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# For first sentence\n",
        "x_1 = Input(shape=(1,), dtype=tf.string)\n",
        "f = embedded_cnn(x_1)  # weight x_f here\n",
        "\n",
        "# For second sentence\n",
        "x_2 = Input(shape=(1,), dtype=tf.string)\n",
        "s = embedded_cnn(x_2)  # weight x_s here\n",
        "\n",
        "# For third sentence\n",
        "x_3 = Input(shape=(1,), dtype=tf.string)\n",
        "t = embedded_cnn(x_3)  # weight x_t here"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2QTAKx8TLdAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fs = Dense(units=SIMILARITY_LAYER,\n",
        "               activation='relu')(Concatenate()([f, t]))  # M_fs here\n",
        "\n",
        "# # Similarity between second and third sentence\n",
        "# # NOTE: I've used a dense layer instead of similarity matrix to get the similarity score\n",
        "# st = Dense(units=SIMILARITY_LAYER,\n",
        "#                activation='relu')(Concatenate()([s, t]))  # M_st here\n",
        "\n",
        "join_layer = Concatenate()([fs, f, s, t])\n",
        "\n",
        "hidden = Dense(units=HIDDEN_LAYER,\n",
        "                   activation='relu')(join_layer)\n",
        "hidden = Dropout(0.5)(hidden)\n",
        "classifcation = Dense(units=4,\n",
        "                        activation='softmax')(hidden)\n",
        "\n",
        "model = Model(inputs=[x_1, x_2, x_3], outputs=classifcation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUzrdS38Ll7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1FFYUFRuqhw",
        "colab_type": "code",
        "outputId": "25e68c2d-01fb-43c1-bc2f-5dc6ba6f799b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None, 1024)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, None, 1024)   0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 128)          590336      lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 128)          590336      lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           lstm_1[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, None, 1024)   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 62)           15934       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 128)          590336      lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 446)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          57216       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4)            516         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,844,674\n",
            "Trainable params: 1,844,674\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F5mSixI9Gq2_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving the model pics\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_layer_names=True, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfB6Re1hPtAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def for_model(convs):\n",
        "  X = [[],[],[]]\n",
        "  \n",
        "  for con in convs:\n",
        "    for i in range(3):\n",
        "      X[i].append(con[i])\n",
        "      \n",
        "  return X\n",
        "x_train_ = for_model(x_train)\n",
        "x_test_ = for_model(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_r7MAG4arVH",
        "colab_type": "code",
        "outputId": "7b29e50f-1c78-480a-99f0-b5d896bccda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://e77536d5.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XdfFzHjFa6HJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tensorboard = TensorBoardColabCallback(tbc ,write_images=True, write_graph=True, update_freq='batch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wn3E4C9adP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=4, \\\n",
        "                          verbose=1, mode='auto', restore_best_weights=True)\n",
        "checkpointer = ModelCheckpoint(filepath='./weights_all.hdf5', verbose=1, save_best_only=True, save_weights_only=True, monitor='val_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OujNz0DKPFVz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train_,\n",
        "          y_train,\n",
        "          validation_data=(x_test_,y_test),\n",
        "          shuffle=True,\n",
        "          batch_size=64,\n",
        "          epochs=30,\n",
        "          callbacks=[checkpointer,tensorboard,earlystop],\n",
        "          initial_epoch=0,\n",
        "          class_weight=class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_7gs093DjWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('./weights_all.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1fapev_U32O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "    if len(loss_list) == 0:\n",
        "        print('Loss is missing in history')\n",
        "        return \n",
        "    \n",
        "    ## As loss always exists\n",
        "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "    ## Loss\n",
        "    plt.figure(1)\n",
        "    for l in loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    for l in val_loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    ## Accuracy\n",
        "    plt.figure(2)\n",
        "    for l in acc_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "    for l in val_acc_list:    \n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAWwzNr7KD_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgN3UYAHeb27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SUibEywfehb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getMetrics(predictions, ground):\n",
        "    \"\"\"\n",
        "    FROM: Baseline/starting_kit\n",
        "\n",
        "    Given predicted labels and the respective ground truth labels, display some metrics\n",
        "    Input: shape [# of samples, NUM_CLASSES]\n",
        "        predictions : Model output. Every row has 4 decimal values, with the highest belonging to the predicted class\n",
        "        ground : Ground truth labels, converted to one-hot encodings. A sample belonging to Happy class will be [0, 1, 0, 0]\n",
        "    Output:\n",
        "        accuracy : Average accuracy\n",
        "        microPrecision : Precision calculated on a micro level. Ref - https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
        "        microRecall : Recall calculated on a micro level\n",
        "        microF1 : Harmonic mean of microPrecision and microRecall. Higher value implies better classification\n",
        "    \"\"\"\n",
        "    # [0.1, 0.3 , 0.2, 0.1] -> [0, 1, 0, 0]\n",
        "    discretePredictions = to_categorical(predictions.argmax(axis=1))\n",
        "\n",
        "    truePositives = np.sum(discretePredictions * ground, axis=0)\n",
        "    falsePositives = np.sum(np.clip(discretePredictions - ground, 0, 1), axis=0)\n",
        "    falseNegatives = np.sum(np.clip(ground - discretePredictions, 0, 1), axis=0)\n",
        "\n",
        "    print(\"True Positives per class : \", truePositives)\n",
        "    print(\"False Positives per class : \", falsePositives)\n",
        "    print(\"False Negatives per class : \", falseNegatives)\n",
        "\n",
        "    # ------------- Macro level calculation ---------------\n",
        "    macroPrecision = 0\n",
        "    macroRecall = 0\n",
        "    # We ignore the \"Others\" class during the calculation of Precision, Recall and F1\n",
        "    for c in range(1, 4):\n",
        "        precision = truePositives[c] / (truePositives[c] + falsePositives[c])\n",
        "        macroPrecision += precision\n",
        "        recall = truePositives[c] / (truePositives[c] + falseNegatives[c])\n",
        "        macroRecall += recall\n",
        "        f1 = (2 * recall * precision) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        print(\"Class %s : Precision : %.3f, Recall : %.3f, F1 : %.3f\" % (label2emotion[c], precision, recall, f1))\n",
        "\n",
        "    macroPrecision /= 3\n",
        "    macroRecall /= 3\n",
        "    macroF1 = (2 * macroRecall * macroPrecision) / (macroPrecision + macroRecall) if (\n",
        "                                                                                             macroPrecision + macroRecall) > 0 else 0\n",
        "    print(\"Ignoring the Others class, Macro Precision : %.4f, Macro Recall : %.4f, Macro F1 : %.4f\" % (\n",
        "        macroPrecision, macroRecall, macroF1))\n",
        "\n",
        "    # ------------- Micro level calculation ---------------\n",
        "    truePositives = truePositives[1:].sum()\n",
        "    falsePositives = falsePositives[1:].sum()\n",
        "    falseNegatives = falseNegatives[1:].sum()\n",
        "\n",
        "    print(\"Ignoring the Others class, Micro TP : %d, FP : %d, FN : %d\" % (\n",
        "        truePositives, falsePositives, falseNegatives))\n",
        "\n",
        "    microPrecision = truePositives / (truePositives + falsePositives)\n",
        "    microRecall = truePositives / (truePositives + falseNegatives)\n",
        "\n",
        "    microF1 = (2 * microRecall * microPrecision) / (microPrecision + microRecall) if (\n",
        "                                                                                             microPrecision + microRecall) > 0 else 0\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    ground = ground.argmax(axis=1)\n",
        "    accuracy = np.mean(predictions == ground)\n",
        "\n",
        "    print(\"Accuracy : %.4f, Micro Precision : %.4f, Micro Recall : %.4f, Micro F1 : %.4f\" % (\n",
        "        accuracy, microPrecision, microRecall, microF1))\n",
        "    return accuracy, microPrecision, microRecall, microF1\n",
        "getMetrics(predictions, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDxTdvNpX-uo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hemovu5KqMKB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing Upload \n",
        "\n",
        "A file called `test.txt` is created which needs to be zipped  and uploaded to the the platform\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BiEv10g28fKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_, convs = preprocessData('devwithoutlabels.txt',mode='test')\n",
        "testing = for_model(convs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "201xpXU3f8-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = model.predict(testing, batch_size=2, verbose=1)\n",
        "predictions = predictions.argmax(axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GOQ3Ku8rkFTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with io.open('test.txt', \"w\", encoding=\"utf8\") as fout:\n",
        "  fout.write('\\t'.join([\"id\", \"turn1\", \"turn2\", \"turn3\", \"label\"]) + '\\n')        \n",
        "  with io.open('devwithoutlabels.txt', encoding=\"utf8\") as fin:\n",
        "    fin.readline()\n",
        "    for lineNum, line in enumerate(fin):\n",
        "      fout.write('\\t'.join(line.strip().split('\\t')[:4]) + '\\t')\n",
        "      fout.write(label2emotion[predictions[lineNum]] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}